{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "#load the dateset\n",
    "import pandas as pd\n",
    "\n",
    "#load the dataset, no header\n",
    "df = pd.read_csv('lercio_headlines.csv', header=None)\n",
    "\n",
    "#record with the maximum number of characters\n",
    "max = df[0].str.len().max()\n",
    "print(max)\n",
    "\n",
    "# pad the headlines with special characters to make them all the same length\n",
    "df[0] = df[0].str.pad(max, side='right', fillchar='~')\n",
    "\n",
    "# insert a special character at the beginning of each headline\n",
    "df[0] = \"^\" + df[0]\n",
    "\n",
    "\n",
    "# create a txt file with the headlines\n",
    "with open('lercio_padded.txt', 'w') as f:\n",
    "    for line in df[0]:\n",
    "        f.write(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lercio dataset is more or less 3 times smaller than the shakespeare dataset that is the baseline for the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.49661225746843"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the mean length of the headlines\n",
    "df[0].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [--filename FILENAME] [--model MODEL]\n",
      "                [--n_epochs N_EPOCHS] [--print_every PRINT_EVERY]\n",
      "                [--hidden_size HIDDEN_SIZE] [--n_layers N_LAYERS]\n",
      "                [--learning_rate LEARNING_RATE] [--chunk_len CHUNK_LEN]\n",
      "                [--batch_size BATCH_SIZE] [--shuffle] [--cuda]\n",
      "train.py: error: unrecognized arguments: ./lercio_headlines_base.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"./lercio_headlines_base.txt\"\n",
    "\n",
    "options =\\\n",
    "\"--model            gru   \" +\\\n",
    "\"--n_epochs         700    \" +\\\n",
    "\"--print_every      50   \" +\\\n",
    "\"--hidden_size      32    \" +\\\n",
    "\"--n_layers         4     \" +\\\n",
    "\"--learning_rate    0.01  \" +\\\n",
    "\"--chunk_len        100   \" +\\\n",
    "\"--batch_size       1000   \" +\\\n",
    "\"--cuda                   \" \n",
    "\n",
    "command = f\"python ./char-rnn-pytorch/train.py {path} {options}\"\n",
    "\n",
    "\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/ispr/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/matteo/anaconda3/envs/ispr/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matteo/ispr/midterm_3/./char-rnn-pytorch/generate.py\", line 54, in <module>\n",
      "    decoder = torch.load(args.filename)\n",
      "  File \"/home/matteo/anaconda3/envs/ispr/lib/python3.10/site-packages/torch/serialization.py\", line 815, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/matteo/anaconda3/envs/ispr/lib/python3.10/site-packages/torch/serialization.py\", line 1043, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/matteo/anaconda3/envs/ispr/lib/python3.10/site-packages/torch/nn/modules/rnn.py\", line 325, in __setstate__\n",
      "    for w in self._flat_weights]\n",
      "  File \"/home/matteo/anaconda3/envs/ispr/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1614, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'GRU' object has no attribute '_flat_weights'. Did you mean: '_all_weights'?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"../lercio_headlines_base.pt\"\n",
    "\n",
    "options =\\\n",
    "'--prime_str   \" \"    ' +\\\n",
    "\"--predict_len    100    \" +\\\n",
    "\"--cuda               \" \n",
    "#\"--temperature    100     \" +\n",
    "\n",
    "\n",
    "command = f\"python ./char-rnn-pytorch/generate.py {path} {options}\"\n",
    "\n",
    "os.system(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"parole.txt\" file contains an list of words in italian (almost complete in my opinion, around 1 milion words), including: compound words, names, surnames, cities and locations, verbs, adjectives, adverbs, etc.\n",
    "\n",
    "The idea is to use that file to calculate the percetage of correct words generate by the model with different hidden size, number of layers and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the file \"parole.txt\" and read it creating a dictionary\n",
    "\n",
    "real_words = {}\n",
    "with open('parole.txt', 'r') as f:\n",
    "    for p in f:\n",
    "        real_words[p.strip().lower()] = True\n",
    "\n",
    "len(real_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/ispr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgenerate\u001b[39;00m \u001b[39mimport\u001b[39;00m generate\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m generate(\u001b[39m\"\u001b[39;49m\u001b[39m./models/lercio_padded.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0.8\u001b[39;49m)\n",
      "File \u001b[0;32m~/ispr/midterm_3/generate.py:45\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(filename, temperature)\u001b[0m\n\u001b[1;32m     42\u001b[0m cuda \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     44\u001b[0m decoder \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(filename,  map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> 45\u001b[0m \u001b[39mprint\u001b[39m(_generate(decoder, prime_str\u001b[39m=\u001b[39;49mprime_str, predict_len\u001b[39m=\u001b[39;49m\u001b[39m168\u001b[39;49m, temperature\u001b[39m=\u001b[39;49mtemperature, cuda \u001b[39m=\u001b[39;49m cuda ))\n",
      "File \u001b[0;32m~/ispr/midterm_3/generate.py:12\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(decoder, prime_str, predict_len, temperature, cuda)\u001b[0m\n\u001b[1;32m      9\u001b[0m prime_input \u001b[39m=\u001b[39m Variable(char_tensor(prime_str)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m cuda:\n\u001b[0;32m---> 12\u001b[0m     hidden \u001b[39m=\u001b[39m hidden\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m     13\u001b[0m     prime_input \u001b[39m=\u001b[39m prime_input\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     14\u001b[0m predicted \u001b[39m=\u001b[39m prime_str\n",
      "File \u001b[0;32m~/anaconda3/envs/ispr/lib/python3.9/site-packages/torch/cuda/__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from generate import generate\n",
    "import torch\n",
    "\n",
    "\n",
    "generate(\"./models/lercio_padded.pt\", 0.8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ispr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
